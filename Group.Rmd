---
title: "Group"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("ggplot2")
library("boot")
library("ISLR")
library("MASS")
library("mclust")
library("KernSmooth")
library("reshape2")
library("mlbench")
library("rpart")
library("partykit")
library("rpart.plot")
library("randomForest")
library("e1071")
```

```{r}
d_full <- read.csv("labeled.csv")

# check duplicates
d_full[duplicated(d_full[,2:8]),]

# check missing values
d_full<-na.omit(d_full)

# change all predictors as numeric variables
d_full[,c(2:8)] <- as.numeric(unlist(d_full[,c(2:8)]))

# change Class as character
d_full$Class = as.factor(d_full$Class)
```

```{r}
# boxplot of  predictors VS each Class
boxplot(d_full$Area~d_full$Class, main = "Boxplot of Area")
boxplot(d_full$Perimeter~d_full$Class, main = "Boxplot of Perimeter")
boxplot(d_full$MajorAxisLength~d_full$Class, main = "Boxplot of MajorAxisLength")
boxplot(d_full$MinorAxisLength~d_full$Class, main = "Boxplot of MinorAxisLength")
boxplot(d_full$Eccentricity~d_full$Class, main = "Boxplot of Eccentricity")
boxplot(d_full$ConvexArea~d_full$Class, main = "Boxplot of ConvexArea")
boxplot(d_full$Extent~d_full$Class, main = "Boxplot of Extent")
```

```{r}
seker<-cali<-d_full[d_full$Class=="SEKER",]
bombay<-d_full[d_full$Class=="BOMBAY",]
cali<-d_full[d_full$Class=="CALI",]
horoz<-d_full[d_full$Class=="HOROZ",]
sira<-d_full[d_full$Class=="SIRA",]
dermason<-d_full[d_full$Class=="DERMASON",]

# Area
print("Outliers for Area in each class")
boxplot.stats(bombay$Area)$out
boxplot.stats(cali$Area)$out
boxplot.stats(dermason$Area)$out
boxplot.stats(horoz$Area)$out
boxplot.stats(seker$Area)$out
boxplot.stats(sira$Area)$out

# Perimeter
print("Outliers for Perimeter in each class")
boxplot.stats(bombay$Perimeter)$out
boxplot.stats(cali$Perimeter)$out
boxplot.stats(dermason$Perimeter)$out
boxplot.stats(horoz$Perimeter)$out
boxplot.stats(seker$Perimeter)$out
boxplot.stats(sira$Perimeter)$out

# MajorAxisLength
print("Outliers for MajorAxisLength in each class")
boxplot.stats(bombay$MajorAxisLength)$out
boxplot.stats(cali$MajorAxisLength)$out
boxplot.stats(dermason$MajorAxisLength)$out
boxplot.stats(horoz$MajorAxisLength)$out
boxplot.stats(seker$MajorAxisLength)$out
boxplot.stats(sira$MajorAxisLength)$out

# MinorAxisLength
print("Outliers for MinorAxisLength in each class")
boxplot.stats(bombay$MinorAxisLength)$out
boxplot.stats(cali$MinorAxisLength)$out
boxplot.stats(dermason$MinorAxisLength)$out
boxplot.stats(horoz$MinorAxisLength)$out
boxplot.stats(seker$MinorAxisLength)$out
boxplot.stats(sira$MinorAxisLength)$out

# Eccentricity
print("Outliers for Eccentricity in each class")
boxplot.stats(bombay$Eccentricity)$out
boxplot.stats(cali$Eccentricity)$out
boxplot.stats(dermason$Eccentricity)$out
boxplot.stats(horoz$Eccentricity)$out
boxplot.stats(seker$Eccentricity)$out
boxplot.stats(sira$Eccentricity)$out

# ConvexArea
print("Outliers for ConvexArea in each class")
boxplot.stats(bombay$ConvexArea)$out
boxplot.stats(cali$ConvexArea)$out
boxplot.stats(dermason$ConvexArea)$out
boxplot.stats(horoz$ConvexArea)$out
boxplot.stats(seker$ConvexArea)$out
boxplot.stats(sira$ConvexArea)$out

# Extent
print("Outliers for Extent in each class")
boxplot.stats(bombay$Extent)$out
boxplot.stats(cali$Extent)$out
boxplot.stats(dermason$Extent)$out
boxplot.stats(horoz$Extent)$out
boxplot.stats(seker$Extent)$out
boxplot.stats(sira$Extent)$out
```

```{r}
set.seed(12345)
trn <- sample(1:3000,1800, replace = FALSE)
dat.trn <- d_full[trn,]
dat.tst <- d_full[-trn,]
```

# Decision tree

```{r}
set.seed(12345)
# original decision tree
rc <- rpart.control(minsplit=10, xval=10, maxdepth=30,cp=0)
myTree <- rpart(Class~Area + Perimeter + MajorAxisLength + MinorAxisLength + Eccentricity + ConvexArea + Extent, data=dat.trn, method='class',parms=list(split='information'), control=rc)
rpart.plot(myTree,type=1,extra=3,branch=1)

# check cp table and find how to prune tree
printcp(myTree)
plotcp(myTree)

# Based on cp table, we can find that nsplit = 16 have min xerror
treeFit <- prune(myTree, cp=0.0026936)
rpart.plot(treeFit,type=1,extra=3,branch=1)
printcp(treeFit)
plotcp(treeFit)
```

```{r}
# Confusion Matrix
pred <- predict(treeFit, newdata = dat.tst,type="class")
table(dat.tst$Class,pred)

# 0.8692
```

# RandomForest

```{r}
set.seed(12345)
forest<-randomForest(Class~Area + Perimeter + MajorAxisLength + MinorAxisLength + Eccentricity + ConvexArea + Extent, data=dat.trn,ntree=200,important=TRUE,proximity=TRUE) 
plot(forest)
forest
```

```{r}
predR<-predict(forest, newdata=dat.tst[,c(2:8)])
table(dat.tst$Class,predR)

# accuracy 0.8883
```

# SVM

```{r}
set.seed(12345)
svm_model <- svm(Class ~ Area + Perimeter + MajorAxisLength + MinorAxisLength + Eccentricity + ConvexArea + Extent, data=dat.trn, kernel = "radial", type = "C-classification")
svm_model
```

```{r}
# Confusion Matrix
predS <- predict(svm_model, newdata = dat.tst,type="class")
table(dat.tst$Class,predS)

# accuracy 0.8833
```

# LDA

```{r}
set.seed(12345)
lda1<- lda(Class ~ Area + Perimeter + MajorAxisLength + MinorAxisLength + Eccentricity + ConvexArea + Extent, data=dat.trn)
lda1
```

```{r}
# Confusion Matrix
lda.probs = predict(lda1, dat.tst)
table(dat.tst$Class, lda.probs$class)

# accuracy 0.8525
```

# QDA

```{r}
set.seed(12345)
qda1<- qda(Class ~ Area + Perimeter + MajorAxisLength + MinorAxisLength + Eccentricity + ConvexArea + Extent, data=dat.trn)
qda1
```

```{r}
# Confusion Matrix
qda.probs = predict(qda1, dat.tst)
table(dat.tst$Class, qda.probs$class)

# accuracy 0.9
```

#KNN
```{r}
set.seed(12345)
AR <- NULL
for (k in 1:30 ) {
test <- knn.cv(dat.trn[,2:8],dat.trn[,9], k)
AR[k] <- sum(test==dat.trn$Class)/length(dat.trn$Class)
}
which(AR==max(AR))

# k=29

# ?k=19
```

```{r}
set.seed(12345)
knn.fit <- knn(dat.trn[,2:8], dat.tst[,2:8], dat.trn$Class, k=29)
table(dat.tst$Class, knn.fit)

# accuracy 0.6975
```
